{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data from raw data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\stryk\\\\Desktop\\\\car make classification\\\\car-make-classification\\\\data_images_testing'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata_splitter\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mmodel\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Run this command [pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118] to download cuda compatible pytorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# First split data into train and test splits\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[43mdata_splitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_images_testing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Next, run training function with default params\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# results_benchmark, results_ht, modelObj = model.train(os.path.join(os.path.dirname(os.getcwd()), 'data_split'))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# print(results_benchmark)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\initScripts\\data_splitter.py:9\u001b[0m, in \u001b[0;36msplitData\u001b[1;34m(rawDataPath)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplitData\u001b[39m(rawDataPath) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Get car make folder paths    \u001b[39;00m\n\u001b[0;32m      8\u001b[0m     rawDataFolderPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rawDataPath)\n\u001b[1;32m----> 9\u001b[0m     carMakeFolders \u001b[38;5;241m=\u001b[39m [folder \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawDataFolderPath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rawDataFolderPath, folder))]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Define train and test split ratio\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     train_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\stryk\\\\Desktop\\\\car make classification\\\\car-make-classification\\\\data_images_testing'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import data_splitter, model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Run this command [pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118] to download cuda compatible pytorch\n",
    "\n",
    "    # First split data into train and test splits\n",
    "    data_splitter.splitData(os.path.join(os.path.dirname(os.getcwd()), 'data_images_testing'))\n",
    "    \n",
    "    # Next, run training function with default params\n",
    "    results_benchmark, results_ht, modelObj = model.train(os.path.join(os.path.dirname(os.getcwd()), 'data_split'))\n",
    "    print(results_benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\runs\\classify\\train6\\weights\\best.engine for TensorRT inference...\n",
      "c:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\data_split\\test\\perodua_axia\\1424422055025-1_2023-11-30T22_45_04.676066_4f1333fa8d2e4ed88f54b2ced032a321_Honda_Freed_white_Sedan_2674_4,406,111,442.jpg\n",
      "\n",
      "0: 640x640 perodua_axia 0.38, toyota_vios 0.34, perodua_myvi 0.27, 1.0ms\n",
      "Speed: 11.0ms preprocess, 1.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run inference check on 3 random files\n",
    "subpath = f'{os.path.dirname(os.getcwd())}\\\\data_split\\\\test'\n",
    "test_axia_path = f'{subpath}\\\\perodua_axia\\\\'\n",
    "test_myvi_path = f'{subpath}\\\\perodua_myvi\\\\'\n",
    "test_vios_path = f'{subpath}\\\\toyota_vios\\\\'\n",
    "\n",
    "random_axia_img = data_splitter.random_image(test_axia_path)\n",
    "random_myvi_img = data_splitter.random_image(test_axia_path)\n",
    "random_vios_img = data_splitter.random_image(test_axia_path)\n",
    "\n",
    "inf_results = modelObj([random_vios_img, random_myvi_img, random_axia_img], stream = True)\n",
    "\n",
    "for result in inf_results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics YOLOv8.2.82  Python-3.12.0 torch-2.4.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3060 Ti, 8192MiB)\n",
      "WARNING  INT8 export requires a missing 'data' arg for calibration. Using default 'data=imagenet10'.\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'c:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\runs\\classify\\train6\\weights\\best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 3) (2.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.2s, saved as 'c:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\runs\\classify\\train6\\weights\\best.onnx' (5.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.3.0...\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(-1, 3, -1, -1) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(-1, 3) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m WARNING  'dynamic=True' model requires max batch size, i.e. 'batch=16'\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building INT8 engine as c:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\runs\\classify\\train6\\weights\\best.engine\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m collecting INT8 calibration images from 'data=imagenet10'\n",
      "\n",
      "Dataset not found , missing path C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10, attempting download...\n",
      "Downloading https://ultralytics.com/assets/imagenet10.zip to 'C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71.1k/71.1k [00:00<00:00, 3.76MB/s]\n",
      "Unzipping C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10.zip to C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10...: 100%|██████████| 24/24 [00:00<00:00, 1923.07file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (2.5s), saved to \u001b[1mC:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10\\train... found 12 images in 10 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10\\val... found 12 images in 10 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10\\val\\n01440764... 0 images, 12 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<00:00, 688.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  No labels found in C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10\\val\\n01440764.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "New cache created: C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10\\val\\n01440764.cache\n",
      "WARNING  No labels found in C:\\Users\\stryk\\Desktop\\car make classification\\datasets\\imagenet10\\val\\n01440764.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m WARNING  >300 images recommended for INT8 calibration, found 12 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success  108.1s, saved as 'c:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\runs\\classify\\train6\\weights\\best.engine' (3.3 MB)\n",
      "\n",
      "Export complete (108.2s)\n",
      "Results saved to \u001b[1mC:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\runs\\classify\\train6\\weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=c:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\runs\\classify\\train6\\weights\\best.engine imgsz=224 int8 \n",
      "Validate:        yolo val task=classify model=c:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\runs\\classify\\train6\\weights\\best.engine imgsz=224 data=c:\\Users\\stryk\\Desktop\\car make classification\\car-make-classification\\data_split int8 \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\stryk\\\\Desktop\\\\car make classification\\\\car-make-classification\\\\runs\\\\classify\\\\train6\\\\weights\\\\best.engine'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dynamic not needed assuming camera models will be of similar make and model\n",
    "# half not needed as that does 16 bit quantization only\n",
    "# simplify optional\n",
    "# workspace and batch keep as default for now\n",
    "modelObj.export(format = 'engine', int8 = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
